# ğŸ“¦ Lab: ReplicaSet - Garantizando la alta disponibilidad de tus Pods

Este laboratorio te guiarÃ¡ paso a paso para entender y usar **ReplicaSet** en Kubernetes. AprenderÃ¡s a asegurar que una aplicaciÃ³n siempre tenga el nÃºmero de rÃ©plicas deseado, incluso si los pods fallan o se eliminan.

> **Pre-requisitos:**
>
>   * Docker Desktop y Minikube instalados y ejecutÃ¡ndose.
>   * Una terminal (PowerShell o Git Bash) con `kubectl` configurado para interactuar con Minikube.
>   * Inicia Minikube con el comando `minikube start`.

-----

1.  ğŸš« El Problema: Un Pod solitario no es resiliente

Imagina que despliegas un Pod para tu aplicaciÃ³n, pero este Pod por alguna razÃ³n deja de funcionar. En un entorno de producciÃ³n, esto significa que tu servicio estarÃ­a caÃ­do. Sin un controlador que lo supervise, Kubernetes no harÃ¡ nada para recuperarlo.

Vamos a probarlo. Crea el siguiente manifiesto `unstable-pod.yaml`:

```yaml
# unstable-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: mi-pod-solitario
  labels:
    app: mi-app
spec:
  containers:
  - name: servidor-web
    image: nginx
    ports:
    - containerPort: 80
```

```bash
# Crea el Pod
kubectl apply -f unstable-pod.yaml

# Revisa el estado del Pod
kubectl get pods
# ğŸ¯ Salida esperada: El Pod estÃ¡ en estado "Running"
# NAME                READY   STATUS    RESTARTS   AGE
# mi-pod-solitario    1/1     Running   0          10s
```

Ahora, simulemos un fallo eliminando el Pod manualmente.

```bash
# âŒ Eliminemos el Pod
kubectl delete pod mi-pod-solitario

# Verifiquemos si se ha recuperado
kubectl get pods
# âŒ Salida esperada: No hay pods con ese nombre.
# No resources found in default namespace.
```

**âŒ Â¿Por quÃ© no funciona?** El Pod ha sido eliminado y Kubernetes no ha hecho nada para reemplazarlo. Un Pod por sÃ­ solo no tiene capacidad de autocuraciÃ³n. Necesitamos un controlador que se encargue de "observar" y "reconciliar" el estado deseado.

-----

2.  âœ… La SoluciÃ³n: Presentamos ReplicaSet

**ReplicaSet** es un controlador que asegura que un nÃºmero especÃ­fico de rÃ©plicas de pods (especificado en el campo `spec.replicas`) se estÃ©n ejecutando en todo momento. Si un pod falla, ReplicaSet lo crea de nuevo automÃ¡ticamente.

Creemos un manifiesto llamado `my-replicaset.yaml` para nuestra aplicaciÃ³n:

```yaml
# my-replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mi-replicaset
spec:
  replicas: 3 # ğŸ¯ NÃºmero de rÃ©plicas que queremos mantener
  selector:
    matchLabels:
      app: mi-app # ğŸ¯ Selector para que ReplicaSet encuentre sus Pods
  template: # ğŸ¯ Plantilla para crear nuevos Pods
    metadata:
      labels:
        app: mi-app
    spec:
      containers:
      - name: servidor-web
        image: nginx
        ports:
        - containerPort: 80
```

```bash
# Aplica el manifiesto
kubectl apply -f my-replicaset.yaml

# Verifica que el ReplicaSet se ha creado y sus Pods
kubectl get rs
# ğŸ¯ Salida esperada: Un ReplicaSet con 3 rÃ©plicas listas
# NAME            DESIRED   CURRENT   READY   AGE
# mi-replicaset   3         3         3       10s

# Revisa los Pods creados por el ReplicaSet
kubectl get pods -l app=mi-app
# ğŸ¯ Salida esperada: 3 Pods en estado "Running"
# NAME                      READY   STATUS    RESTARTS   AGE
# mi-replicaset-abcde       1/1     Running   0          10s
# mi-replicaset-fghij       1/1     Running   0          10s
# mi-replicaset-klmno       1/1     Running   0          10s
```

Ahora, **simulemos el fallo** de uno de los pods eliminÃ¡ndolo.

```bash
# âŒ Elimina uno de los Pods (el nombre serÃ¡ diferente)
kubectl delete pod mi-replicaset-abcde

# Observa cÃ³mo ReplicaSet crea uno nuevo casi inmediatamente
kubectl get pods -l app=mi-app
# ğŸ¯ Salida esperada: A pesar de la eliminaciÃ³n, el nÃºmero de pods sigue siendo 3. ReplicaSet ha creado uno nuevo.
# NAME                      READY   STATUS    RESTARTS   AGE
# mi-replicaset-fghij       1/1     Running   0          1m
# mi-replicaset-klmno       1/1     Running   0          1m
# mi-replicaset-pqrst       1/1     Running   0          5s
```

**ğŸ¯ Resultado:** ReplicaSet ha actuado como un guardiÃ¡n, detectando que el nÃºmero de rÃ©plicas no coincidÃ­a con el deseado (`replicas: 3`) y creando un nuevo Pod para restaurar el estado deseado.

-----

3.  ğŸ“Š VerificaciÃ³n y Casos PrÃ¡cticos

#### Escalar horizontalmente

Una de las grandes ventajas de ReplicaSet es su capacidad para escalar tu aplicaciÃ³n de forma sencilla. Aumentemos el nÃºmero de rÃ©plicas a 5.

```bash
# Escala el ReplicaSet a 5 rÃ©plicas
kubectl scale --replicas=5 rs mi-replicaset

# Verifica que se han creado los nuevos Pods
kubectl get rs mi-replicaset
# ğŸ¯ Salida esperada: El nÃºmero de rÃ©plicas deseadas y actuales es 5.
# NAME            DESIRED   CURRENT   READY   AGE
# mi-replicaset   5         5         5       2m

kubectl get pods -l app=mi-app
# ğŸ¯ Salida esperada: Ahora hay 5 pods en total
```

#### Etiquetado y Selectores

Los `labels` y `selectors` son la clave para que ReplicaSet sepa quÃ© Pods debe gestionar. Cambia una etiqueta de un Pod para ver cÃ³mo ReplicaSet lo "abandona".

```bash
# ObtÃ©n el nombre de un Pod
kubectl get pods -l app=mi-app -o jsonpath='{.items[0].metadata.name}'
# ğŸ¯ Salida esperada: mi-replicaset-xxxxx

# Remueve la etiqueta `app: mi-app` de un pod
kubectl label pod [NOMBRE_DEL_POD] app-

# Ahora, verifica el estado. ReplicaSet crearÃ¡ un nuevo Pod para mantener el total de 5.
kubectl get pods -l app=mi-app
# ğŸ¯ Salida esperada: 5 Pods con la etiqueta `app: mi-app`.
# El Pod que modificaste ya no estÃ¡ en la lista.
```

#### MÃºltiples ReplicaSets

Puedes tener mÃºltiples ReplicaSets, cada uno gestionando su propio conjunto de Pods. Esto es Ãºtil para separar entornos o versiones. Crea uno nuevo para una "versiÃ³n 2".

```yaml
# replicaset-v2.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mi-replicaset-v2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mi-app-v2
  template:
    metadata:
      labels:
        app: mi-app-v2
    spec:
      containers:
      - name: servidor-web
        image: busybox # Usamos una imagen diferente para distinguir
        command: ["sh", "-c", "echo 'Hola desde la v2!' && sleep 3600"]
```

```bash
kubectl apply -f replicaset-v2.yaml

kubectl get rs
# ğŸ¯ Salida esperada: Dos ReplicaSets, cada uno con sus rÃ©plicas.
# NAME                 DESIRED   CURRENT   READY   AGE
# mi-replicaset        5         5         5       10m
# mi-replicaset-v2     2         2         2       10s
```

-----

5.  ğŸ§¹ Limpieza

Elimina los ReplicaSets para limpiar todos los recursos, incluyendo los Pods que crearon.

```bash
# Elimina los ReplicaSets
kubectl delete rs mi-replicaset mi-replicaset-v2

# Confirma que los recursos se han eliminado
kubectl get rs
# ğŸ¯ Salida esperada: No se encuentran recursos.
# No resources found in default namespace.
```

-----

6.  ğŸ“ QuÃ© Aprendiste

  * Aprendiste que los **Pods** por sÃ­ solos no son resilientes.
  * Descubriste cÃ³mo **ReplicaSet** actÃºa como un controlador para mantener un nÃºmero fijo de rÃ©plicas de tus Pods.
  * Comprendiste la importancia de los **selectores (selectors)** y las **etiquetas (labels)** para que ReplicaSet identifique quÃ© pods debe gestionar.
  * Practicaste cÃ³mo **escalar** tus aplicaciones horizontalmente usando `kubectl scale`.
  * Viste cÃ³mo ReplicaSet automÃ¡ticamente **reemplaza** un Pod fallido o eliminado, garantizando la alta disponibilidad.

> ğŸ¯ **Regla de oro:** ReplicaSet es tu guardiÃ¡n. Su Ãºnico trabajo es asegurar que el nÃºmero de rÃ©plicas sea siempre el que has deseado, sin importar lo que pase.
